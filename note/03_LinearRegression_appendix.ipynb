{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_LinearRegression_appendix.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmI+SQAW1SHUhILopvRXGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bayashi-cl/statistical-learning/blob/main/note/03_LinearRegression_appendix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 最小二乗推定に関する補足\n",
        "\n",
        "最小二乗推定量 $\\hat{\\beta}$ は正規方程式を利用して次のように求めていた。\n",
        "\n",
        "$$\\hat{\\beta} = (X^\\top X)X^\\top y$$\n",
        "\n",
        "しかし、この方法ではいくつかの問題点が存在する。\n",
        "* $X$ が正則でない場合に $\\hat{\\beta}$ を求めることができない\n",
        "* 時間計算量がパラメーター数を $p$ として $O(p^3)$ であるため、パラメーターが増えると計算が遅くなる。\n",
        "\n",
        "これらの問題に対処するためのいくつかの手法を示す。"
      ],
      "metadata": {
        "id": "ubKZu-bsH0G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Xが（行・列）フルランクの場合：QR分解\n",
        "\n",
        "$A$ が行、または列でフルランクの場合 $A=QR$ と分解できる。ここで、 $Q$ は直交行列であり、 $R$ は上三角行列である。よって、最小二乗推定量は\n",
        "\n",
        "$$\\hat{\\beta} = R^{-1}Q^\\top y$$\n",
        "\n",
        "で求められる。"
      ],
      "metadata": {
        "id": "qEJhgFZ4StID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. $X$ が正則でない場合：特異値分解(SVD)\n",
        "\n",
        "$X$ の**Moore-Penrose一般逆行列**（擬似逆行列）$X^+$ を以下の条件を満たす行列と定義する。\n",
        "1. $XX^+X = X$\n",
        "1. $X^+XX^+=X$\n",
        "1. $(X^+X)^\\top = X^+X$\n",
        "1. $(XX^+)^\\top = XX^+$\n",
        "\n",
        "任意の行列 $A$ は $A = U\\Sigma V^\\top$ と分解できる、ただし、 $U,V$ は\n",
        "直交行列、 $\\Sigma$ は $A$ の特異値からなる対角行列である。\n",
        "\n",
        "また、 $A^+$ は $A^+ = U\\Sigma^+V$ と分解でき、 $\\Sigma^+$ は特異値の逆数からなる対角行列になる。\n",
        "\n",
        "最小二乗推定量は\n",
        "\n",
        "$$\\hat\\beta = X^+y$$\n",
        "\n",
        "となる。この方法はQR分解より非効率的である。"
      ],
      "metadata": {
        "id": "1_EK-yBVNKCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 計算量が問題になる場合：勾配降下法\n",
        "\n",
        "解析的に解くことを諦めて、**勾配降下法**を使う。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BjWr5cTKVaog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 各ライブラリで利用可能な手法\n",
        "\n",
        "|言語|ライブラリ|||\n",
        "|:-:|:-:|:--|:--|\n",
        "|R     |stats::lm|QR分解|[リンク](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/lm.html)|\n",
        "|Python|statsmodels.regression.linear_model.OLS|擬似逆行列/qr分解|[リンク](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit.html#statsmodels.regression.linear_model.OLS.fit)|\n",
        "|Python|mlxtend.regressor.LinearRegression|閉形式/QR分解/特異値分解/勾配降下法/確率的勾配降下法|[リンク](http://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression/)|\n",
        "|Python|sklearn.linear_model.LinearRegression|不明(xGELSD?)|[リンク](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)|"
      ],
      "metadata": {
        "id": "9fXHtm-7V8ld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "44WRqwvdHlSl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 参考\n",
        "* ［第3版］Python機械学習プログラミング 達人データサイエンティストによる理論と実践\n",
        "ISBN: 978-4295010074\n",
        "* データ分析基礎線形代数の基礎知識 (増強版)\n",
        "[リンク](http://ds.k.kyoto-u.ac.jp/e-learning_files/data_analysis_basic/slide-03a.pdf)\n",
        "* mlxtend User Guide LinearRegression\n",
        "[リンク](https://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression/)\n",
        "* 【解説】 一般逆行列\n",
        "[リンク](https://www.slideshare.net/wosugi/ss-79624897)"
      ],
      "metadata": {
        "id": "kUf0Wx27Lnw-"
      }
    }
  ]
}