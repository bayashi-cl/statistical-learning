{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bayashi-cl/statistical-learning/blob/main/note/03_LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-avUL4vJ4OH"
      },
      "source": [
        "from math import sqrt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.formula.api as smf\n",
        "import plotly.express as px\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiE4dy2TAUNf"
      },
      "source": [
        "ad = pd.read_csv(\"https://www.statlearning.com/s/Advertising.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1gNXT2_APvL"
      },
      "source": [
        "X = ad['TV'].to_numpy()\n",
        "Y = ad['sales'].to_numpy()\n",
        "x_bar = X.mean()\n",
        "y_bar = Y.mean()\n",
        "n = len(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERSRA0fq5vEN"
      },
      "source": [
        "# 3 線形回帰\n",
        "\n",
        "線形回帰の特徴\n",
        "* 教師あり学習\n",
        "* シンプル\n",
        "* 定量的な予測に強い\n",
        "\n",
        "今後に出てくる学習の手法は線形回帰を発展させたものが多い。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JairJ-E656s"
      },
      "source": [
        "`Advertising`のデータからマーケティングプランを提案するにはどのような情報が必要だろうか。\n",
        "\n",
        "以下のような問題について考える。\n",
        "\n",
        "1. そもそも広告費と売上の間に関係性はあるか。\n",
        "1. その関係はどれくらい強いのか。\n",
        "1. どのメディアがどれだけ売上に貢献しているか。\n",
        "1. 売上の予測はどれくらい正確か。\n",
        "1. 関係性は線形か。\n",
        "1. メディア間の相乗効果は存在するのか。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96aAqKGL9vfw"
      },
      "source": [
        "## 3.1 単回帰\n",
        "\n",
        "単回帰では $Y$ を目的変数、 $X$ を説明変数として、\n",
        "\n",
        "$$Y \\approx \\beta_0 + \\beta_1X$$\n",
        "\n",
        "のようなモデルを考える。例えば`sales`と`TV`の関係なら、\n",
        "\n",
        "$$\\textrm{sales} \\approx \\beta_0 + \\beta_1 \\times \\textrm{TV}$$\n",
        "\n",
        "として $\\hat{\\beta}$ を求める。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUKuOCbBCZ-A"
      },
      "source": [
        "### 3.1.1 パラメータの推定\n",
        "\n",
        "まずは**最小二乗法**で考える（他の考え方は6章で）。\n",
        "\n",
        "$\\hat{y}_i = \\hat{\\beta_0}+\\hat{\\beta_1}x_i$ を $i$ 番目のデータに対する推定値として残差を $e_i = y_i - \\hat{y_i}$ とする。\n",
        "\n",
        "ここで**残差平方和**(*residual sum of squares (RSS)*)を\n",
        "\n",
        "$$\\textrm{RSS} = e_1^2+ \\cdots + e_n^2$$\n",
        "\n",
        "と定義してこれを最小化すると、\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "  \\hat{\\beta_1} &= \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\\\\n",
        "  \\hat{\\beta_0} &= \\bar{y}-\\hat{\\beta_1}\\bar{x}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "となる。\n",
        "\n",
        "実際に計算をする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZRW7yPUJ-NQ"
      },
      "source": [
        "numerator = 0.0\n",
        "denominator = 0.0\n",
        "\n",
        "for xi, yi in zip(X, Y):\n",
        "  numerator += (xi - x_bar) * (yi - y_bar)\n",
        "  denominator += (xi - x_bar)**2\n",
        "\n",
        "beta_hat_1 = numerator / denominator\n",
        "beta_hat_0 = y_bar - beta_hat_1 * x_bar\n",
        "\n",
        "min_rss = 0.0\n",
        "for xi, yi in zip(X, Y):\n",
        "  yi_hat = beta_hat_0 + beta_hat_1 * xi\n",
        "  min_rss += (yi - yi_hat)**2\n",
        "\n",
        "\n",
        "print(f\"sales   = {beta_hat_0:.5f} + {beta_hat_1:.5f} * TV\")\n",
        "print(f\"min RSS = {min_rss:.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxcYJ3mLN_T6"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(ad['TV'], ad['sales'])\n",
        "reg_x = np.linspace(0, 300, 100)\n",
        "reg_y = beta_hat_0 + beta_hat_1 * reg_x\n",
        "ax.plot(reg_x, reg_y, color=\"red\", label=\"Regression\")\n",
        "ax.set(xlabel=\"TV\", ylabel=\"sales\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p2CRqruRz_4"
      },
      "source": [
        "sz = 50\n",
        "b0_ = np.linspace(beta_hat_0 - 2, beta_hat_0 + 2, sz)\n",
        "b1_ = np.linspace(beta_hat_1 - 0.02, beta_hat_1 + 0.02, sz)\n",
        "b0, b1 = np.meshgrid(b0_, b1_, indexing='xy')\n",
        "rss = np.zeros((sz, sz))\n",
        "\n",
        "for (i, j), _ in np.ndenumerate(rss):\n",
        "    rss[i, j] = ((Y - (b0[i, j] + X * b1[i, j]))**2).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBvv7o9XWoMy"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "cont = ax.contour(b0, b1, rss, cmap=plt.cm.Set1, levels=[2110, 2150, 2200, 2300, 2500, 3000])\n",
        "cont.clabel(fmt='%1.0f', fontsize=10)\n",
        "ax.scatter(beta_hat_0, beta_hat_1, label=r\"$\\hat{\\beta}$\")\n",
        "ax.set(xlabel=r\"$\\beta_0$\", ylabel=r\"$\\beta_1$\", title=\"RSS\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3rnZpG_cyJV"
      },
      "source": [
        "### 3.1.2 推定値の制度の評価\n",
        "\n",
        "母集団に対してこのモデルをあてはめると $X$ と $Y$の関係は\n",
        "\n",
        "$Y = \\beta_0 + \\beta_1X + \\epsilon$\n",
        "\n",
        "この式は**母集団回帰線** *(population regression line)* と呼ばれ、誤差項 $\\epsilon$ はこのモデルで見逃している要素（他の変数や観測誤差など）を表す。\n",
        "\n",
        "最小二乗法による推定は母集団回帰線に一致するとは限らないが、不偏性があるので観測を繰り返せば正確になっていく。\n",
        "\n",
        "$\\hat{\\beta_0}$ と $\\hat{\\beta_1}$ の分散はそれぞれ、\n",
        "\n",
        "$$\n",
        "\\textrm{SE}(\\hat{\\beta_0})^2 = \\sigma^2\\left[ \\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\textrm{SE}(\\hat{\\beta_1})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\n",
        "$$\n",
        "\n",
        "厳密には誤差 $\\epsilon$ が共通の分散を持ち無相関である必要があるが、そうでなくても近似として有効である。\n",
        "\n",
        "$x$がバラけていたほうが$\\hat{\\beta_1}$ の分散が小さくなり、少ないデータで正確な推定ができるようになる。\n",
        "\n",
        "$\\sigma^2$ は未知だが、データから推定することができ、その推定量 $\\textrm{RSE} = \\sqrt{\\textrm{RSS}/(n-2)}$ を**残差標準偏差** *(residual standard error)* と呼ぶ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr5fWtf3yEUJ"
      },
      "source": [
        "標準偏差は信頼区間の推定にも使うことができ、その95%信頼区間はそれぞれ\n",
        "\n",
        "$$\\hat{\\beta_1} \\pm 2 \\cdot \\textrm{SE}(\\hat{\\beta_1})$$\n",
        "$$\\hat{\\beta_0} \\pm 2 \\cdot \\textrm{SE}(\\hat{\\beta_0})$$\n",
        "\n",
        "で構成される。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAdzKK_o4pXr"
      },
      "source": [
        "sns.regplot(data=ad, x=\"TV\", y=\"sales\", line_kws={'color': 'orange'})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u2Uo5dh2EOe"
      },
      "source": [
        "$X$ と $Y$ に関係性があるかは次の検定により確認できる。\n",
        "\n",
        "$$\n",
        "H_0:\\beta_1 = 0\\\\\n",
        "H_1:\\beta_1 \\ne 0\n",
        "$$\n",
        "\n",
        "t統計量が標準偏差のばらつきを無視できるほど大きければ帰無仮説をrejectできる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_kllR3IDIQ0"
      },
      "source": [
        "model_TV = ols(formula='sales ~ TV', data=ad).fit()\n",
        "model_newspaper = ols(formula='sales ~ newspaper', data=ad).fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rek777w4J71"
      },
      "source": [
        "print(model_TV.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCG3-M347jCh"
      },
      "source": [
        "### 3.1.3 モデルの精度を評価する\n",
        "\n",
        "モデルがデータにどれくらいフィットしているかを知りたい。\n",
        "\n",
        "通常、**$R^2$統計量**と**残差標準誤差** *residual standard error (RSE)* で評価される。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHil5r0S-i3I"
      },
      "source": [
        "#### 残差標準誤差\n",
        "\n",
        "大雑把に言うと、RSEと真の回帰直線から予測値が平均してどれだけ離れているかを表す数値であり、次の式で表される。\n",
        "\n",
        "$$\\textrm{RSE} = \\sqrt{\\frac{1}{n-2}\\textrm{RSS}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiz5SsuZ_3GF"
      },
      "source": [
        "rse = sqrt(1 / (n - 2) * min_rss)\n",
        "print(f\"RSE = {rse:.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNxXJTdSDJ_j"
      },
      "source": [
        "#### $R^2$統計量\n",
        "\n",
        "RSEは単位が $Y$ に依存するのでそれによらない統計量が欲しい。\n",
        "\n",
        "$$R^2 = \\frac{\\textrm{TSS}-\\textrm{RSS}}{\\textrm{TSS}} = 1-\\frac{\\textrm{RSS}}{\\textrm{TSS}}$$\n",
        "\n",
        "ここで、$\\textrm{TSS}=\\sum(y_i-\\bar{y})^2$ は**全平方和** *(total sum of squares)*\n",
        "\n",
        "RSSが回帰を行った後の予測のばらつきを表すのに対して、TSSは回帰を行う前のばらつきを表す。よって $R^2$ 統計量は回帰によりどれだけのばらつきが除去されたかを表し、1に近いほどより多くの要素が回帰によって説明されたことになる。\n",
        "\n",
        "単回帰の場合は$R^2$統計量は相関係数の2乗と一致するが、次の重回帰では有用である。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPAhw6wKN3uX"
      },
      "source": [
        "corr2 = np.corrcoef(X, Y)[1, 0]**2\n",
        "print(f\"corr^2 = {corr2:.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5DklIkjIeOB"
      },
      "source": [
        "## 3.2 重回帰\n",
        "\n",
        "単回帰を拡張し、次のようなモデルを考える。\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_pX_p + \\epsilon$$\n",
        "\n",
        "`Advertising`の例では次のようになる。\n",
        "\n",
        "$$\\textrm{sales} = \\beta_0 + \\beta_1\\times\\textrm{TV} + \\beta_2\\times\\textrm{radio} + \\beta_3\\times\\textrm{newspaper} + \\epsilon$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVHHMkSdDrF2"
      },
      "source": [
        "model_TV_radio= ols(formula='sales ~ TV + radio', data=ad).fit()\n",
        "model_TV_radio_newspaper= ols(formula='sales ~ TV + radio + newspaper', data=ad).fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QNoS8M8KCld"
      },
      "source": [
        "### 3.2.1 回帰係数の推定\n",
        "\n",
        "単回帰の場合を自然に拡張して推定が可能。\n",
        "\n",
        "得られる係数は他の要素を固定した状態での変化量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13r7S_5MK5Bf"
      },
      "source": [
        "print(model_TV_radio_newspaper.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyJ8CUuhp913"
      },
      "source": [
        "print(model_TV_radio.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-NZ_BHhMR6m"
      },
      "source": [
        "print(model_newspaper.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgxQet1MM4vx"
      },
      "source": [
        "ad.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNty3FX0L08G"
      },
      "source": [
        "`newspaper`に注目すると、単回帰では売上との関係が認められるが、重回帰では認められないという結果になっている。重回帰による結果が正しいと仮定し`radio`と`newspaper`の相関係数が大きいことに注目すると、`radio`が大きいと`sales`も`newspaper`も大きくなるという疑似相関が見えてくる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghMgwMtuPe_b"
      },
      "source": [
        "### 3.2.2 いくつかの重要な疑問\n",
        "\n",
        "1. 説明変数 $X_1, X_2, \\ldots, X_p$のうち有用なものは存在するのか。\n",
        "1. すべての予測変数がYを説明するのに役立つか，一部の予測変数だけが有用なのか\n",
        "1. モデルはどのくらいデータに適合しているか？\n",
        "1. 説明変数のセットが与えられた場合、どのような推定をすべきか。そして、その推定はどのくらい正確か。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrHr_H_xWdWn"
      },
      "source": [
        "#### 1 説明変数と推定値に関係はあるか\n",
        "\n",
        "以下の検定を考える\n",
        "\n",
        "$H_0:\\beta_1 = \\cdots = \\beta_p = 0$ v.s. $H_1:$ 少なくとも1つの $\\beta_j$ が非ゼロ\n",
        "\n",
        "f統計量を使う。\n",
        "\n",
        "$$F = \\frac{(\\textrm{TSS}-\\textrm{RSS})/p}{\\textrm{RSS}/(n-p-1)}$$\n",
        "\n",
        "帰無仮説が正しければ $E[(\\textrm{TSS}-\\textrm{RSS})/p] = \\sigma^2$ となり、$F$ は1に近い値になる。一方、対立仮説が正しければ $E[\\textrm{RSS}/(n-p-1)] = \\sigma^2$ となり、 $E[(\\textrm{TSS}-\\textrm{RSS})/p] > \\sigma^2$ となるため、$F$ は1よりも大きい値になる。\n",
        "\n",
        "棄却域は $n$ と $p$ に依存する。詳しくは現代数理統計学の11.3節へ\n",
        "\n",
        "`Advertising`ではF統計量が1よりも非常に大きいことから、少なくとも1つのメディアが売上増加と関連しているという極めて強い証拠が得られる。\n",
        "\n",
        "説明変数が多いとp値を個別に見ただけではそれが偶然小さい値をとっているだけの可能性があるが、F統計量は説明変数の数を調整しているため、そのような問題が発生しない。\n",
        "\n",
        "$p>n$ の場合にはそもそも最小二乗法が使えないため、前方選択や6章に出てくる手法を使うことになる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBEtad5MgVy0"
      },
      "source": [
        "#### 2 どの変数が重要か\n",
        "\n",
        "大抵の場合、全ての説明変数が目的変数に関係しているわけではない。理想的には全てのモデルを作り、比較することで **変数選択** を行う必要がある。比較の際に基準となる統計情報については\n",
        "* 赤池情報量基準(AIC)\n",
        "* ベイズ情報量基準(BIC)\n",
        "* adjusted $R^2$\n",
        "\n",
        "などがある。 \n",
        "\n",
        "しかし、この方法では $2^p$ 個のモデルを作ることになり、嬉しくない。よって効率化が必要である。\n",
        "\n",
        "古典的には以下のような手法がある。\n",
        "\n",
        "##### 前方選択\n",
        "切片のみの状態から、単回帰を行いRSSが小さい順に変数を貪欲に追加していく。余分な変数を含んでしまうことがある。\n",
        "\n",
        "##### 後方選択\n",
        "全ての変数が選択された状態からp値が大きい順に除去していく。$p>n$ のときは使えない。\n",
        "\n",
        "##### 混合選択\n",
        "前方選択を行い、p値が一定値を上回った場合にその変数を除去する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFgzat_vokbG"
      },
      "source": [
        "##### 3 モデルの適合度\n",
        "\n",
        "単回帰のときと同じようにRSEと$R^2$を使う\n",
        "\n",
        "重回帰の場合、 $R^2 = \\textrm{Cor}(Y, \\hat{Y})^2$ となる。\n",
        "\n",
        "$R^2$の値が1に近いとき、そのモデルが分散の大部分を説明できていることになる。\n",
        "\n",
        "`TV`と`radio`のモデルと`TV`と`radio`と`newspaper`のモデルを比較すると、 $R^2$ がほとんど変化していない（実際には微増）ことから、過学習が発生している可能性があり、`newspaper`が除外できる事がわかる。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePyrr8Pavbc5"
      },
      "source": [
        "def calc_rse(model, Y_, data):\n",
        "  y_hat = model.predict(data)\n",
        "  p = len(model.params) - 1\n",
        "  n = len(data)\n",
        "  return sqrt(1 / (n - p - 1) * ((Y_ - y_hat)**2).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1OKHg2guVBs"
      },
      "source": [
        "rse_TV = calc_rse(model_TV, Y, ad)\n",
        "rse_TV_radio = calc_rse(model_TV_radio, Y, ad)\n",
        "rse_multi = calc_rse(model_TV_radio_newspaper, Y, ad)\n",
        "print(f\"RSE TV                     = {rse_TV:.5f}\")\n",
        "print(f\"RSE TV & radio             = {rse_TV_radio:.5f}\")\n",
        "print(f\"RSE TV & radio & newspaper = {rse_multi:.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvMkLCvyPMj"
      },
      "source": [
        "`TV`から`TV & radio`ではRSEが減少しているのに対して`TV & radio`から`TV & radio & newspaper`ではRSEが増加している。これは重回帰のRSEが\n",
        "\n",
        "$$\\textrm{RSE} = \\sqrt{\\frac{1}{n-p-1}\\textrm{RSS}}$$\n",
        "\n",
        "と表されるためである。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeCpD_eb2xYy"
      },
      "source": [
        "error = Y - model_TV_radio.predict(ad)\n",
        "fig = px.scatter_3d(ad, x='TV', y='radio', z='sales', color=error)\n",
        "fig.update_traces(marker_size=2)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jWpkvkA4qrL"
      },
      "source": [
        "グラフからわかるようにこのデータは線形ではなく2つのメディアを利用すると相乗効果がありそう。\n",
        "\n",
        "3.3.2ではこのようなことを考慮に入れる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HLi90kF5jyT"
      },
      "source": [
        "##### 予測\n",
        "\n",
        "予測にあたってモデルの式をそのまま使うと3つの不確実性が生じる。\n",
        "\n",
        "1. 推定値は真の値とは異なる　-> 信頼区間を考える\n",
        "1. 線形モデルは現実の（線形でない）モデルの表面を近似しているに過ぎない。 -> 無視\n",
        "1. 真の$\\beta$がわかったとしても $\\epsilon$ による誤差が存在する。 -> 区間で予測する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzqYG7EdJVG1"
      },
      "source": [
        "credit = pd.read_csv(\"https://www.statlearning.com/s/Credit.csv\")\n",
        "credit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkjhbUAzL6XA"
      },
      "source": [
        "credit_d = pd.get_dummies(credit, columns=[\"Own\", \"Region\"])\n",
        "credit_d.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppo5EXGLHOKg"
      },
      "source": [
        "## 3.3 回帰モデルにおけるその他の検討事項\n",
        "\n",
        "### 3.3.1 質的な予測因子\n",
        "\n",
        "例えば`Credit` には\n",
        "* 家の所有\n",
        "* 学生か\n",
        "* 配偶者の有無\n",
        "* 出身地域(東部・西部・南部)\n",
        "\n",
        "といった質的変数が存在する。\n",
        "\n",
        "質的変数を回帰モデルに組み込むにはダミー変数を作成する。\n",
        "\n",
        "$$\n",
        "x_i = \n",
        "\\begin{cases}\n",
        "  1 & 家を持っている場合 \\\\\n",
        "  0 & 家を持っていない場合\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "$$y_i = \\beta_0 + \\beta_1x_i+\\epsilon$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORZLAe7jOC-x"
      },
      "source": [
        "model_own = ols(formula='Balance ~ Own_Yes', data=credit_d).fit()\n",
        "print(model_own.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSTq_B7aO57d"
      },
      "source": [
        "$$\n",
        "x_{i1} = \n",
        "\\begin{cases}\n",
        "  1 & 南部出身 \\\\\n",
        "  0 & 南部出身でない\n",
        "\\end{cases}\\\\\n",
        "x_{i2} = \n",
        "\\begin{cases}\n",
        "  1 & 西部出身 \\\\\n",
        "  0 & 西部出身でない\n",
        "\\end{cases}\n",
        "$$\n",
        "$$y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\epsilon$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0pGvDfJPmeL"
      },
      "source": [
        "model_region = ols(formula='Balance ~ Region_South + Region_West', data=credit_d).fit()\n",
        "print(model_region.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ny-ErHHQnvz"
      },
      "source": [
        "### 3.3.2 線形モデルの拡張\n",
        "\n",
        "線形モデルでは $X$ と $Y$ の間にと加法性と線形性が成り立つという仮定をおいていた。\n",
        "* 加法性：$X_i$ と $Y$ の関係が他の説明変数に依存しないこと。\n",
        "* 線形性：$X_i$ の変化による $Y$ の変化が他の説明変数に依存せず一定であること。\n",
        "\n",
        "これらの仮定を緩和するための古典的な手法を示す。\n",
        "\n",
        "#### 加法性の緩和\n",
        "\n",
        "`Advertising`に対して次のような**相互作用項**を含むモデルを考える\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_1X_2 + \\epsilon$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZs-gHuULV7"
      },
      "source": [
        "model_inter_TV_radio = ols(formula=\"sales ~ TV + radio + TV*radio\", data=ad).fit()\n",
        "print(model_inter_TV_radio.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wy-pGMlVvTX"
      },
      "source": [
        "`TV`と`radio`のみのモデルよりも$R^2$が大きくなっている。また、相互作用項のp値も小さいため、この項をモデルに含めるべきだということがわかる。\n",
        "\n",
        "単体の場合のp値が小さくなくてもそれらの相互作用項のp値が小さくなることがある。\n",
        "\n",
        "質的変数に対しても相互作用を考えることができる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcap36YzaiNu"
      },
      "source": [
        "auto = pd.read_csv(\"https://www.statlearning.com/s/Auto.csv\", na_values='?').dropna()\n",
        "auto.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1c6nUWBae3R"
      },
      "source": [
        "#### 非線形モデル\n",
        "\n",
        "多項式回帰を用いて非線形関係に対応する。\n",
        "\n",
        "`Auto`に対してモデル\n",
        "\n",
        "$$\\textrm{mpg} = \\beta_0 + \\beta_1\\times\\textrm{horsepower} + \\beta_2\\times\\textrm{horsepower}^2 + \\epsilon$$\n",
        "\n",
        "を考える。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eg7MEKkb9jT"
      },
      "source": [
        "model_horse = ols(formula=\"mpg ~ horsepower\", data=auto).fit()\n",
        "print(model_horse.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q3zL_5eeAgE"
      },
      "source": [
        "def pow2(data):\n",
        "  return data * data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFQsdhjAdIdq"
      },
      "source": [
        "model_horse2 = ols(formula=\"mpg ~ horsepower + pow2(horsepower)\", data=auto).fit()\n",
        "print(model_horse2.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frEYCTZEed-W"
      },
      "source": [
        "2乗の項をモデルに加えたほうが良さそうに見える。さらに5乗の項まで加えると次のようになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNopXs_Eeknx"
      },
      "source": [
        "plt.scatter(data=auto, x=\"horsepower\", y=\"mpg\",alpha=0.5) \n",
        "sns.regplot(data=auto, x=\"horsepower\", y=\"mpg\", ci=None, label='Linear', scatter=False, color='orange')\n",
        "sns.regplot(data=auto, x=\"horsepower\", y=\"mpg\", ci=None, label='Degree 2', order=2, scatter=False, color='green')\n",
        "sns.regplot(data=auto, x=\"horsepower\", y=\"mpg\", ci=None, label='Degree 5', order=5, scatter=False, color='red')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJmSfsQYf6UI"
      },
      "source": [
        "5乗の回帰曲線は不自然に曲がっており、データへの適合度が上がったかどうか不明。詳しくは7章で\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaVFxnPeh3vk"
      },
      "source": [
        "### 3.3.3 問題点\n",
        "\n",
        "データセットに線形回帰モデルを適用すると問題が起こることがある。代表的なものは\n",
        "\n",
        "#### 1 非線形関係によるもの\n",
        "残差をプロットすることで識別する。説明変数に対して非線形変換をすることで対応する。\n",
        "\n",
        "#### 2 誤差の相関関係\n",
        "誤差項の間に相関関係があると真の標準誤差を過小に評価してしまう。結果、信頼区間や予測区間が狭くなったり、p値を低く計算してしまう。隣り合うデータに正の相関がある誤差を持つ時系列データで発生することが多い。\n",
        "\n",
        "時系列データ以外にもサンプルの選び方が適切でないと誤差に相関が発生することがある。\n",
        "\n",
        "#### 3 誤差の一定でない分散\n",
        "例えば、 $X$ の値が大きほど分散が大きくなることがある。凹関数を使って　$Y$ を変換して対処する。\n",
        "\n",
        "#### 4 外れ値\n",
        "外れ値は最小二乗推定量にはあまり影響を及ぼさないが、RSEや$R^2$などには影響を与える。\n",
        "\n",
        "外れ値を見つけるには残差プロットが有効。どこからを外れ値とするかは残差をその標準偏差の推定量で割ったスチューデント化残差をプロットすることで見つける事ができる。\n",
        "\n",
        "#### 5 高レバレッジ値\n",
        "$x_i$ が　他の $x$から離れている場合、 $x_i$ は高いレバレッジを持つ。\n",
        "\n",
        "高レバレッジ値を削除すると、最小二乗推定量に与える影響が大きい。\n",
        "\n",
        "判定にはレバレッジ統計量を使う。単回帰の場合には\n",
        "\n",
        "$$h_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{i'=1}^n(x_{i'} - \\bar{x})^2}$$\n",
        "\n",
        "レバレッジ統計量が $(p+1)/n$ を大きく超える場合、そのデータが高いレバレッジを持っていることが考えられる。\n",
        "\n",
        "#### 6 共線性\n",
        "2つの説明変数が密接に関係している状態を指す。\n",
        "\n",
        "このような場合には、個々の変数の効果を分離することが困難になったり、最小二乗推定量の精度が低下したりする。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioLusJGm950x"
      },
      "source": [
        "## 3.4 マーケティング・プラン"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lfIjiHN9-Jk"
      },
      "source": [
        "## 3.5 線形回帰とk近傍法の比較\n"
      ]
    }
  ]
}